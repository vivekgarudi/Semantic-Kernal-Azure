{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d90b0c13",
   "metadata": {},
   "source": [
    "# Step 1 Install all python libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da651d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m pip install semantic-kernel==0.3.10.dev0\n",
    "!python -m pip install azure-devops\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c460e218",
   "metadata": {},
   "source": [
    "# Step 2 Import Packages required to prepare a semantic kernel instance first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd150646",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import dotenv_values\n",
    "import semantic_kernel as sk\n",
    "from semantic_kernel import ContextVariables, Kernel # Context to store variables and Kernel to interact with the kernel\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, OpenAIChatCompletion # AI services\n",
    "from semantic_kernel.planning.sequential_planner import SequentialPlanner # Planner\n",
    "\n",
    "kernel = sk.Kernel() # Create a kernel instance\n",
    "kernel1 = sk.Kernel() #create another kernel instance for not having semanitc function in the same kernel \n",
    "\n",
    "useAzureOpenAI = True\n",
    "\n",
    "# Configure AI service used by the kernel\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_chat_service(\"chat_completion\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel1.add_chat_service(\"chat_completion\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_chat_service(\"chat-gpt\", OpenAIChatCompletion(\"gpt-3.5-turbo\", api_key, org_id))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "589733c5",
   "metadata": {},
   "source": [
    "# Step 3 Importing semantic skills and function from folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0183226",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note: using skills from the samples folder\n",
    "plugins_directory = \"./plugins\"\n",
    "\n",
    "    # Import the semantic functions\n",
    "DevFunctions=kernel1.import_semantic_skill_from_directory(plugins_directory, \"AzureDevOps\")\n",
    "FDesFunction = DevFunctions[\"FeatureDescription\"]  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0410c8b",
   "metadata": {},
   "source": [
    "# Step 4 calling the semantic function with feature title to genrate feature description based on predefined template\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cdc4b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "  \n",
    "resultFD = FDesFunction(\"Azure Resource Group Configuration Export and Infrastructure as Code (IAC) Generation\")\n",
    "\n",
    "print(resultFD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a272559d",
   "metadata": {},
   "source": [
    "# Step 5 Importing native function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28b36011",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugins.AzureDevops.native_function import feature\n",
    "azdev = kernel.import_skill(feature(kernel1), skill_name=\"AzureDevOps\")\n",
    "variables = ContextVariables()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "697a4930",
   "metadata": {},
   "source": [
    "# Step 6 Executing native function by puttingÂ natural language queries in title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa4a604",
   "metadata": {},
   "outputs": [],
   "source": [
    "variables[\"title\"] = \"creating a nice pipelines\"\n",
    "variables[\"description\"] = \"test\"\n",
    "result = await kernel.run_async(\n",
    "                azdev[\"create\"], input_vars=variables\n",
    "            )\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece07768",
   "metadata": {},
   "source": [
    "# Step 7 Sequential planner to genrate plan to create n number of features to meet requirment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8b09658",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugins.AzureDevops.native_function import feature\n",
    "planner = SequentialPlanner(kernel)\n",
    "# Import the native functions\n",
    "AzDevplugin = kernel.import_skill(feature(kernel1), skill_name=\"AzureDevOps\")\n",
    "ask = \"create two Azure DevOps features for one with title creating user and one with creating work items with standard feature title and description\"\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "for step in plan._steps:\n",
    "        print(step.description, \":\", step._state.__dict__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "212da78d",
   "metadata": {},
   "source": [
    "# Step 8 Sequential planner to execute genrated plan using available function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880239b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Plan results:\")\n",
    "result = await plan.invoke_async(ask)\n",
    "for step in plan._steps:\n",
    "        print(step.description, \":\", step._state.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60fe8f62",
   "metadata": {},
   "source": [
    "-Identify unser stories - Identify user stories from feature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c628b3e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "UDesFunction = DevFunctions[\"IdentifyUserStory\"]    \n",
    "resultUD = UDesFunction(str(resultFD))\n",
    "\n",
    "print(resultUD)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67a17277",
   "metadata": {},
   "source": [
    "Importing and executing **Native plugin** - \n",
    "- Create- It creates feature in azure devops features with nested call to semantic function to genrate feature description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "870c81db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "49cb58e7",
   "metadata": {},
   "source": [
    "Using Basic planner to achive goal by sticking all the fuctions togather."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b61fa8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a70cd98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "subtasks=json.loads(str(plan.generated_plan))\n",
    "subtasks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "164c84dd",
   "metadata": {},
   "source": [
    "Excute plan based on steps from planner function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c61865c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute the plan\n",
    "for index, subtask in enumerate(subtasks, start=1):\n",
    "    result = await planner.execute_plan_async(plan, kernel)\n",
    "    print(\"Plan results:\")\n",
    "    print(result)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7316e0bd",
   "metadata": {},
   "source": [
    "**Sequential planner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from plugins.AzureDevops.Feature_nested import feature\n",
    "planner = SequentialPlanner(kernel)\n",
    "# Import the native functions\n",
    "math_plugin = kernel.import_skill(feature(kernel1), skill_name=\"AzureDevOps\")\n",
    "ask = \"create two Azure DevOps features for one with title creating chai and one with creating work items with standard feature title and description\"\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "for step in plan._steps:\n",
    "        print(step.description, \":\", step._state.__dict__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2ddec5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "print(\"Plan results:\")\n",
    "result = await plan.invoke_async(ask)\n",
    "for step in plan._steps:\n",
    "        print(step.description, \":\", step._state.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "920546df",
   "metadata": {},
   "source": [
    "**Action Planner**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02466e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import ActionPlanner\n",
    "planner = ActionPlanner(kernel)\n",
    "ask = \"create identify Azure DevOps features for one with title office work and one with self learning with standard feature title and description\"\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "for step in plan._steps:\n",
    "        print(step.description, \":\", step._state.__dict__)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50166f9a",
   "metadata": {},
   "source": [
    " Execute sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6fd544",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await plan.invoke_async()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1db9528d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74f9ffae",
   "metadata": {},
   "source": [
    "Importing packages required for preparing and using our our data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e9910c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import (\n",
    "    AzureTextCompletion,\n",
    "    AzureTextEmbedding,\n",
    ")\n",
    "\n",
    "\n",
    "from semantic_kernel.connectors.memory.azure_cognitive_search import (\n",
    "    AzureCognitiveSearchMemoryStore,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca49c74f",
   "metadata": {},
   "source": [
    "Register chat completion end point and Embeded model for preparing memory and quering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccf0ad44",
   "metadata": {},
   "outputs": [],
   "source": [
    "kernel = sk.Kernel()\n",
    "\n",
    "config = dotenv_values(\".env\")\n",
    "COLLECTION_NAME = \"carml-index-sample\"\n",
    "\n",
    "AZURE_COGNITIVE_SEARCH_ENDPOINT = config[\"AZURE_COGNITIVE_SEARCH_ENDPOINT\"]\n",
    "AZURE_COGNITIVE_SEARCH_ADMIN_KEY = config[\"AZURE_COGNITIVE_SEARCH_ADMIN_KEY\"]\n",
    "AZURE_OPENAI_API_KEY = config[\"AZURE_OPENAI_API_KEY\"]\n",
    "AZURE_OPENAI_ENDPOINT = config[\"AZURE_OPENAI_ENDPOINT\"]\n",
    "AZURE_OPENAI_EM_DEPLOYMENT_NAME = config[\"AZURE_OPENAI_EM_DEPLOYMENT_NAME\"]\n",
    "AZURE_OPENAI_DEPLOYMENT_NAME = config[\"AZURE_OPENAI_DEPLOYMENT_NAME\"]\n",
    "vector_size = 1536\n",
    "\n",
    "kernel.add_text_completion_service(\n",
    "        \"dv\",\n",
    "        AzureTextCompletion(\n",
    "            deployment_name=AZURE_OPENAI_DEPLOYMENT_NAME,\n",
    "            endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "        ),\n",
    "    )\n",
    "kernel.add_text_embedding_generation_service(\n",
    "       \"ada\",\n",
    "        AzureTextEmbedding(\n",
    "            deployment_name=AZURE_OPENAI_EM_DEPLOYMENT_NAME,\n",
    "            endpoint=AZURE_OPENAI_ENDPOINT,\n",
    "            api_key=AZURE_OPENAI_API_KEY,\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "344713f6",
   "metadata": {},
   "source": [
    "Initiating Endpoint for connecting with Azure cognitive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9442a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kernel.register_memory_store(memory_store=sk.memory.VolatileMemoryStore())\n",
    "kernel.import_skill(sk.core_skills.TextMemorySkill())\n",
    "connector = AzureCognitiveSearchMemoryStore(\n",
    "        vector_size, AZURE_COGNITIVE_SEARCH_ENDPOINT, AZURE_COGNITIVE_SEARCH_ADMIN_KEY\n",
    "    )\n",
    "\n",
    "    # Register the memory store with the kernel\n",
    "kernel.register_memory_store(memory_store=connector)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95e90352",
   "metadata": {},
   "source": [
    "Populating information in cognitive serach using Embeding model\n",
    "\n",
    "I have some CARML biceps which i am uploading in the cognitive search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c239aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = (r\"C:\\Users\\vigarudi\\Documents\\code\\Powershell\\CARML\\Main\")  # Replace with the path to your folder\n",
    "\n",
    "# List all files in the folder\n",
    "file_list = os.listdir(folder_path)\n",
    "\n",
    "# Iterate through each file and read its contents\n",
    "for filename in file_list:\n",
    "    file_path = os.path.join(folder_path, filename)\n",
    "    \n",
    "    # Check if it's a file (not a directory)\n",
    "    if os.path.isfile(file_path):\n",
    "        with open(file_path, 'r') as file:\n",
    "            file_contents = file.read()\n",
    "            # Now, you can work with the file_contents as a string\n",
    "            await kernel.memory.save_information_async(\n",
    "                COLLECTION_NAME, id=filename, text=file_contents\n",
    "                )\n",
    "            \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "629a9011",
   "metadata": {},
   "source": [
    "searching the data in memory "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998c36d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#serach in memory\n",
    "questions = [\n",
    "        \"how to provision VM\",\n",
    "    ]\n",
    "\n",
    "for question in questions:\n",
    "    print(f\"Question: {question}\")\n",
    "    result = await kernel.memory.search_async(COLLECTION_NAME, question)\n",
    "    print(f\"Answer: {result[0].text}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483e71f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "await connector.close_async()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2c251f6",
   "metadata": {},
   "source": [
    "embeding the search outcome with semantic function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "972f2418",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sk_prompt = \"\"\"\n",
    "    Genrate bicep code to provision {{$user_input}} for example\n",
    "    Example:\n",
    "    - {{$fact1}} {{recall $fact1}} \n",
    "    - {{$fact1}}\n",
    "    \"\"\".strip()\n",
    "\n",
    "\n",
    "\n",
    "context = kernel.create_new_context()\n",
    "context[\"fact1\"] = \"How to provision a VM?\"\n",
    "context[sk.core_skills.TextMemorySkill.COLLECTION_PARAM] = COLLECTION_NAME\n",
    "context[sk.core_skills.TextMemorySkill.RELEVANCE_PARAM] = 0.8\n",
    "context[\"user_input\"] = \"How to provision a VM?\"\n",
    "chat_func = kernel.create_semantic_function(sk_prompt, max_tokens=4000, temperature=0.8)\n",
    "answer = await kernel.run_async(chat_func, input_vars=context.variables)\n",
    "print(answer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e6ec1e7",
   "metadata": {},
   "source": [
    "Using Chat completion with our own data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f9433e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "url = \"https://ch1-open-ai.openai.azure.com/openai/deployments/ContosoDemos-OpenAI-gpt-35-turbo/extensions/chat/completions?api-version=2023-06-01-preview\"\n",
    "headers =  {\"Content-Type\":\"application/json\",\"api-key\": \"a33c3a92d6694dedad2bf1e2fb7a9c48\" }\n",
    "data = '''{\n",
    "    \"dataSources\": [\n",
    "        {\n",
    "            \"type\": \"AzureCognitiveSearch\",\n",
    "            \"parameters\": {\n",
    "                \"endpoint\": \"https://contoso.search.windows.net\",\n",
    "                \"key\": \"aAEeBL5XE83GVHfJqulOn4BBdRpZJ5J7fizBsAWL6jAzSeAf0yNt\",\n",
    "                \"indexName\": \"carml-index-sample\"\n",
    "            }\n",
    "        }\n",
    "    ],\n",
    "    \"messages\": [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"Bicep file that contains code to deploy Azure resources, including virtual machines?\"\n",
    "        }\n",
    "    ]\n",
    "}'''\n",
    "response = requests.post(url, data=data, headers=headers)\n",
    "json_data = json.loads(response.text)\n",
    "print(str(json_data[\"choices\"][0]['messages'][0]['content']))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
